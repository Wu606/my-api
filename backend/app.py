# from flask import Flask, request, jsonify
# from flask_cors import CORS
# import requests
# import jieba
# from collections import Counter
#
# app = Flask(__name__)
# CORS(app)
#
# API_KEY = "sk-e8b9608b5a14425d9e5979cdfcc1f4cc"
# API_URL = "https://api.deepseek.com/v1/chat/completions"
#
# @app.route("/generate", methods=["POST"])
# def generate():
#     data = request.get_json()
#     prompt = data.get("prompt", "")
#     mode = data.get("mode", "default")
#
#     if not prompt and mode != "daily":
#         return jsonify({"error": "ç¼ºå°‘æç¤ºè¯"}), 400
#
#     if mode == "article":
#         prompt = f"è¯·å†™ä¸€ç¯‡å…³äºâ€œ{prompt}â€çš„ä¸­æ–‡æ–‡ç« ï¼Œ300å­—å·¦å³ã€‚"
#     elif mode == "poem":
#         prompt = f"è¯·å†™ä¸€é¦–å…³äºâ€œ{prompt}â€çš„å¤è¯—ã€‚"
#     elif mode == "rewrite":
#         prompt = f"è¯·å°†ä¸‹é¢è¿™å¥è¯æ”¹å†™å¾—æ›´æ–‡è‰ºå¹½é»˜ä¸€ç‚¹ï¼š{prompt}"
#     elif mode == "daily":
#         prompt = "è¯·ç»™æˆ‘ä¸€å¥ AI æ¯æ—¥é‡‘å¥æˆ–è€…åŠ±å¿—é¸¡æ±¤ã€‚"
#
#     headers = {
#         "Authorization": f"Bearer {API_KEY}",
#         "Content-Type": "application/json"
#     }
#
#     body = {
#         "model": "deepseek-chat",
#         "messages": [{"role": "user", "content": prompt}],
#         "temperature": 0.7,
#         "max_tokens": 300
#     }
#
#     try:
#         response = requests.post(API_URL, headers=headers, json=body)
#         result = response.json()
#         content = result['choices'][0]['message']['content']
#         return jsonify({"result": content})
#     except Exception as e:
#         return jsonify({"error": "ç”Ÿæˆå¤±è´¥", "detail": str(e)}), 500
#
# # @app.route("/wordcloud_from_text", methods=["POST"])
# # def wordcloud_from_text():
# #     data = request.get_json()
# #     text = data.get("text", "")
# #
# #     if not text.strip():
# #         return jsonify({"error": "æ–‡æœ¬ä¸ºç©º"}), 400
# #
# #     print("âœ… æ”¶åˆ°ä¸Šä¼ æ–‡æœ¬å†…å®¹ï¼Œå¼€å§‹åˆ†è¯")
# #     words = jieba.lcut(text)
# #     filtered = [w for w in words if len(w.strip()) > 1 and w.isalpha()]
# #     freq = Counter(filtered)
# #     top_words = freq.most_common(30)
# #     result = [{"text": word, "count": count} for word, count in top_words]
# #
# #     print("âœ… è¿”å›å…³é”®è¯ï¼š", result)
# #     return jsonify({"result": result})
# @app.route("/wordcloud_from_text", methods=["POST"])
# def wordcloud_from_text():
#     data = request.get_json()
#     print("ğŸ§ª æ¥æ”¶åˆ°è¯·æ±‚æ•°æ®ï¼š", data)   # åŠ è¿™ä¸€å¥
#     text = data.get("text", "")
#
#     if not text.strip():
#         print("âŒ æ–‡æœ¬ä¸ºç©ºï¼")
#         return jsonify({"error": "æ–‡æœ¬ä¸ºç©º"}), 400
#
#     print("âœ… æ”¶åˆ°ä¸Šä¼ æ–‡æœ¬å†…å®¹ï¼Œå¼€å§‹åˆ†è¯")
#     words = jieba.lcut(text)
#     filtered = [w for w in words if len(w.strip()) > 1 and w.isalpha()]
#     print("ğŸ“Œ åˆ†è¯ç»“æœï¼š", filtered)
#     freq = Counter(filtered)
#     top_words = freq.most_common(30)
#     result = [{"text": word, "count": count} for word, count in top_words]
#
#     print("âœ… è¿”å›å…³é”®è¯ï¼š", result)
#     return jsonify({"result": result})
#
# if __name__ == "__main__":
#     app.run(host="0.0.0.0", port=5000)
from flask import Flask, request, jsonify
from flask_cors import CORS
import requests
import jieba
from collections import Counter
from docx import Document  # Word æ–‡ä»¶å¤„ç†
import base64
import tempfile
import os

app = Flask(__name__)
CORS(app)

API_KEY = "sk-e8b9608b5a14425d9e5979cdfcc1f4cc"
API_URL = "https://api.deepseek.com/v1/chat/completions"

@app.route("/generate", methods=["POST"])
def generate():
    data = request.get_json()
    prompt = data.get("prompt", "")
    mode = data.get("mode", "default")

    if not prompt and mode != "daily":
        return jsonify({"error": "ç¼ºå°‘æç¤ºè¯"}), 400

    if mode == "article":
        prompt = f"è¯·å†™ä¸€ç¯‡å…³äºâ€œ{prompt}â€çš„ä¸­æ–‡æ–‡ç« ï¼Œ300å­—å·¦å³ã€‚"
    elif mode == "poem":
        prompt = f"è¯·å†™ä¸€é¦–å…³äºâ€œ{prompt}â€çš„å¤è¯—ã€‚"
    elif mode == "rewrite":
        prompt = f"è¯·å°†ä¸‹é¢è¿™å¥è¯æ”¹å†™å¾—æ›´æ–‡è‰ºå¹½é»˜ä¸€ç‚¹ï¼š{prompt}"
    elif mode == "daily":
        prompt = "è¯·ç»™æˆ‘ä¸€å¥ AI æ¯æ—¥é‡‘å¥æˆ–è€…åŠ±å¿—é¸¡æ±¤ã€‚"

    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }

    body = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "max_tokens": 300
    }

    try:
        response = requests.post(API_URL, headers=headers, json=body)
        result = response.json()
        content = result['choices'][0]['message']['content']
        return jsonify({"result": content})
    except Exception as e:
        return jsonify({"error": "ç”Ÿæˆå¤±è´¥", "detail": str(e)}), 500


@app.route("/wordcloud_from_text", methods=["POST"])
def wordcloud_from_text():
    data = request.get_json()
    print("ğŸ§ª æ¥æ”¶åˆ°è¯·æ±‚æ•°æ®ï¼š", data)
    text = data.get("text", "")

    if not text.strip():
        print("âŒ æ–‡æœ¬ä¸ºç©ºï¼")
        return jsonify({"error": "æ–‡æœ¬ä¸ºç©º"}), 400

    print("âœ… æ”¶åˆ°ä¸Šä¼ æ–‡æœ¬å†…å®¹ï¼Œå¼€å§‹åˆ†è¯")
    return jsonify({"result": extract_keywords(text)})


@app.route("/wordcloud_from_word", methods=["POST"])
def wordcloud_from_word():
    """
    æ¥æ”¶ base64 ç¼–ç çš„ .docx æ–‡ä»¶å†…å®¹ï¼Œæå–æ–‡å­—ç”Ÿæˆè¯äº‘
    """
    data = request.get_json()
    encoded = data.get("file", "")

    if not encoded:
        return jsonify({"error": "æœªæä¾›æ–‡ä»¶å†…å®¹"}), 400

    try:
        # è§£ç å¹¶å†™å…¥ä¸´æ—¶ Word æ–‡ä»¶
        word_bytes = base64.b64decode(encoded)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
            tmp.write(word_bytes)
            tmp_path = tmp.name

        # è¯»å– Word æ–‡æœ¬å†…å®¹
        doc = Document(tmp_path)
        text = "\n".join([p.text for p in doc.paragraphs])

        os.remove(tmp_path)

        if not text.strip():
            return jsonify({"error": "Word æ–‡ä»¶ä¸ºç©º"}), 400

        print("âœ… Word æ–‡ä»¶è¯»å–æˆåŠŸï¼Œå¼€å§‹åˆ†è¯")
        return jsonify({"result": extract_keywords(text)})

    except Exception as e:
        return jsonify({"error": "Word æ–‡ä»¶å¤„ç†å¤±è´¥", "detail": str(e)}), 500


def extract_keywords(text):
    """é€šç”¨åˆ†è¯ + ç»Ÿè®¡å‡½æ•°"""
    words = jieba.lcut(text)
    filtered = [w for w in words if len(w.strip()) > 1 and w.isalpha()]
    freq = Counter(filtered)
    top_words = freq.most_common(30)
    result = [{"text": word, "count": count} for word, count in top_words]
    print("âœ… è¿”å›å…³é”®è¯ï¼š", result)
    return result


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
